
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110963980-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-110963980-1');
	</script>

  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
	/* Color scheme stolen from Sergey Karayev */
	a {
	color: #1772d0;
	text-decoration:none;
	}
	a:focus, a:hover {
	color: #f09228;
	text-decoration:none;
	}
	body,td,th,tr,p,a {
	font-family: 'Lato', Verdana, Helvetica, sans-serif;
	font-size: 14px
	}
	strong {
	font-family: 'Lato', Verdana, Helvetica, sans-serif;
	font-size: 14px;
	}
	heading {
	font-family: 'Lato', Verdana, Helvetica, sans-serif;
	font-size: 22px;
	}
	papertitle {
	font-family: 'Lato', Verdana, Helvetica, sans-serif;
	font-size: 14px;
	font-weight: 700
	}
	name {
	font-family: 'Lato', Verdana, Helvetica, sans-serif;
	font-size: 32px;
	}
	.one
	{
	width: 160px;
	height: 100px;
	position: relative;
	}
	.two
	{
	width: 160px;
	height: 100px;
	position: absolute;
	transition: opacity .2s ease-in-out;
	-moz-transition: opacity .2s ease-in-out;
	-webkit-transition: opacity .2s ease-in-out;
	}
	.fade {
	 transition: opacity .2s ease-in-out;
	 -moz-transition: opacity .2s ease-in-out;
	 -webkit-transition: opacity .2s ease-in-out;
	}
	span.highlight {
		background-color: #ffffd0;
	}
  </style>
  <link rel="icon" type="image/png" href="https://people.eecs.berkeley.edu/~barron/seal_icon.png">
  <title>Rafael Rafailov</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
	<tr>
	<td>
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	  <tr>
		<td width="67%" valign="middle">
		<p align="center">
		<name>Rafael Rafailov</name><br>
		rafailov at cs dot stanford dot edu
		</p>
		<p>
	  I am a Masters student in Statistics and Computer Science at <a href="https://www.stanford.edu/">Stanford University</a> advised by <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> at the <a href="https://irislab.stanford.edu/">IRIS lab</a>, part of the <a href="https://ai.stanford.edu/">Stanford Artificial Intelligence Laboratory (SAIL)</a>.
	</p>
	<p>
	  Previously, I graduated from <a href="http://www.berkeley.edu/">UC Berkeley</a> with highest honors in
	  <a href="http://math.berkeley.edu/">Applied Mathematics</a>, <a href="http://statistics.berkeley.edu//">Statistics</a> and <a href="https://www.econ.berkeley.edu///">Economics</a>. Before graduate school I was a junior portfolio manager at Goldman Sachs' <a href="https://www.gsam.com/content/gsam/us/en/advisors/market-insights/gsam-insights/quantinomics.html">Quantitative Investment Startegies (QIS) unit</a>.
		</p>
		<p align=center>

<a href="https://scholar.google.com/citations?user=TwABcRgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/rafael-rafailov-1b521611b/">LinkedIn</a>
		</p>
		</td>
		<td width="40%">
		<img src="./files/rafael.png" width="250">
		</td>
	  </tr>
	  </table>

	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr><td>
            <heading>News</heading>
            <ul>
              <li><strong>September 2021</strong>: Two papers accepted at NeurIPS 2021.</li>
              <li><strong>March 2021</strong>: Our paper Offline Reinforcement Learning from Images with Latent Space Models was selected for an Oral presentation at L4DC.</li>
              <li><strong>March 2021</strong>: I gave a talk the the Intel AI on scaling offline model-based Reinforcement Learning.</li>


            </ul>
        </td></tr>

	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	  <tr>
		<td width="100%" valign="middle">
		  <heading>Research</heading>
		  <p>
		My research interests lie at the intersection of machine learning, perception, and control for robotics, specifically deep reinforcement learning, imitation learning and meta-learning.
		  </p>
		</td>
	  </tr>
	  </table>
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">



    <tr onmouseout="combo_stop()" onmouseover="combo_start()">
            <td width="25%">
                  <heading2><i></i></heading2><br>
              <div class="one">
                  <div class="two" id="combo_still" style="opacity: 0;"><img src="./files/combo.png" width=150></div>
                  <img src="./files/combo.png" width=150 >
              </div>
              <script type="text/javascript">
              function combo_start() {
                document.getElementById('combo_still').style.opacity = "1";
              }
     function combo_stop() {
                document.getElementById('combo_still').style.opacity = "0";
              }
              combo_stop()
              </script>

                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/pdf/2102.08363.pdf">
                  <papertitle>COMBO: Conservative Offline Model-Based Policy Optimization</papertitle></a><br>
              <a href="https://cs.stanford.edu/~tianheyu/">Tianhe Yu*</a>,
              <a href="https://aviralkumar2907.github.io/">Aviral Kumar*</a>,
              <strong>Rafael Rafailov</strong>, 
              <a href="https://homes.cs.washington.edu/~aravraj/">Aravind Rajeswaran</a>,
              <a href="http://people.eecs.berkeley.edu/~svlevine">Sergey Levine</a>,
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a><br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em><br>
                <a href="https://arxiv.org/abs/2102.08363">arXiv</a>
                </p><p></p>
                <p>
                Model-based offline RL methods rely on explicit uncertainty quantification for incorporating pessimism, which can be difficult and unreliable with complex models. We overcome this limitation by developing a new model-based offline RL algorithm, COMBO, that regularizes the value function on out-of-support state-action tuples generated via rollouts under the learned model. We show COMBO with theoretical guarantees and also find that COMBO consistently performs as well or better as compared to prior offline model-free and model-based methods on widely studied offline RL benchmarks, including image-based tasks.
                </p>
                </td>
              </tr>



    <tr onmouseout="vmail_stop()" onmouseover="vmail_start()">
            <td width="25%">
                  <heading2><i></i></heading2><br>
              <div class="one">
                  <div class="two" id="vmail_still" style="opacity: 0;"><img src="./files/vmail.png" width=150></div>
                  <img src="./files/vmail.png" width=150 >
              </div>
              <script type="text/javascript">
              function vmail_start() {
                document.getElementById('vmail_still').style.opacity = "1";
              }
     function vmail_stop() {
                document.getElementById('vmail_still').style.opacity = "0";
              }
              vmail_stop()
              </script>

                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/pdf/2107.08829.pdf">
                  <papertitle>Visual Adversarial Imitation Learning using Variational Models</papertitle></a><br>
              <strong>Rafael Rafailov</strong>,
              <a href="https://cs.stanford.edu/~tianheyu/">Tianhe Yu</a>,
              <a href="https://homes.cs.washington.edu/~aravraj/">Aravind Rajeswaran</a>,
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a><br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em><br>
                <a href="https://arxiv.org/abs/2107.08829">arXiv</a>
                </p><p></p>
                <p>
                We develop a variational model-based adversarial imitation learning (V-MAIL) algorithm. The model-based approach provides a strong signal for representation learning, enables sample efficiency, and improves the stability of adversarial training. 
                </p>
                </td>
              </tr>




    <tr onmouseout="lompo_stop()" onmouseover="lompo_start()">
            <td width="25%">
                  <heading2><i></i></heading2><br>
              <div class="one">
                  <div class="two" id="lompo_still" style="opacity: 0;"><img src="./files/lompo.png" width=150></div>
                  <img src="./files/lompo.png" width=150 >
              </div>
              <script type="text/javascript">
              function lompo_start() {
                document.getElementById('lompo_still').style.opacity = "1";
              }
     function lompo_stop() {
                document.getElementById('lompo_still').style.opacity = "0";
              }
              lompo_stop()
              </script>

                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/pdf/2012.11547.pdf">
                  <papertitle>Offline Reinforcement Learning from Images with Latent Space Models</papertitle></a><br>
                <strong>Rafael Rafailov*</strong>, 
              <a href="https://cs.stanford.edu/~tianheyu/">Tianhe Yu*</a>,
              <a href="https://homes.cs.washington.edu/~aravraj/">Aravind Rajeswaran</a>,
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a><br>
                <em>Learning for Decision Making and Control (L4DC), 2021</em><font color="red"><strong> (Oral presentation)</strong></font><br>
                <a href="https://arxiv.org/abs/2012.11547">arXiv</a> / <a href="https://sites.google.com/view/lompo/">website</a>
                </p><p></p>
                <p>
                Model-based offline RL algorithms have achieved state of the art results in state based tasks and have strong theoretical guarantees. However, they rely crucially on the ability to quantify uncertainty in the model predictions, which is particularly challenging with image observations. To overcome this challenge, we propose to learn a latent-state dynamics model, and represent the uncertainty in the latent space. We find that our algorithm significantly outperforms previous offline model-free RL methods as well as state-of-the-art online visual model-based RL methods in both simulated and real-world robotics control tasks.
                </p>
                </td>
              </tr>

    


		


	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Teaching</heading>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <!--<td width="25%"><img src="./files/teach_crop.jpg" alt="teach" width="160" height="160"></td>-->
        <td width="75%" valign="center">
        <p>
        <a href="https://web.stanford.edu/class/cs379c/">
            <papertitle>CS379C: Computational Models of the Neocortex - Spring 2020</papertitle>
        </a>
        <br>
        Course Assistant
        </p>
        <p>

        <p>
        <a href="http://cs330.stanford.edu/">
            <papertitle>CS330: Deep Multi-Task and Meta Learning - Fall 2020</papertitle>
        </a>
        <br>
        Course Assistant
        </p>
        <p>
        <a href="http://cs330.stanford.edu/">
            <papertitle>CS330: Deep Multi-Task and Meta Learning - Fall 2021</papertitle>
        </a>
        <br>
        Head Course Assistant
        </p>
        </td>
      </tr>
      </tbody></table>

	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	  <tr>
		<td>
		<br>
		<p align="right"><font size="2">
		  <a href="http://www.cs.berkeley.edu/~barron/">Template</a>
		  </font>
		</p>
		</td>
	  </tr>
	  </table>
	</td>
	</tr>
  </table>
  </body>
</html>

